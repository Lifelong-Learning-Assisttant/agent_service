# Общее описание

Инструменты (Tools) — реализованы синхронно через httpx.

Client (sync). 
Это нужно потому, что LangChain AgentExecutor.run обычно ожидает sync callables. Если вы хотите полностью async стек — можно использовать AsyncAgentExecutor (зависит от версии LangChain) или обёртку sync_to_async в FastAPI, но это можно добавить позже.

Адаптер LLM

LLMClientWrapper использует LLMClient.generate. Это даёт вам преимущества вашей реализации LLM (ретраи, таймауты и т.д.) в рамках LangChain.

Логирование и отладка

Для отладки поставьте verbose=True при создании LangchainAgentService — LangChain будет печатать шаги reason→tool→observation. 
Для production его лучше выключить.

Совместимость LangChain

если при импорте langchain.llms.base.LLM или langchain.tools.Tool/initialize_agent будет ошибка — напишите версию LangChain (pip show langchain) и я подгоню код под неё.

Капитализация и имена инструментов — Agent будет выбирать инструмент сам (по name и description). Вы можете уточнить description (более длинные инструкции) чтобы направить поведение.

Кэширование / таймауты

Я использовал settings.HTTP_TIMEOUT_S для вызовов MCP; при больших нагрузках рекомендую добавить кэш (Redis) и rate-limit.

Общая концепция

У нас будет очень много инструментов, не факт что они будут запускаться одновременно.
Мне хочется чтобы каждый инструмент поднимался отдельно и независимо в своем докер контейнере, а потом агент просто видел список своих новых инструментов и использовал то что есть в данный момент времени.
Поэтому агент и tavily будут жить отдельно.
А пути где кого искать зададим в отдельном конфиге для агента.

